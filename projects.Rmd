---
title: "Research Projects"
---

## Learning in Dynamic Environments 
Two of the more common assumptions that applied machine learning researchers make when using an algorithm is that: (1) the training & testing data are sampled from a fixed - albeit unknown - probability distribution, and (2) there are an equal number of samples from all classes. The former is referred to as concept drift (a.k.a., learning in non-stationary environments) when new data are presented over time, and the latter is known as class imbalance. Our group is developing novel incremental learning algorithms to explicitly address problems related learning from concept drift and class imbalance, which has been largely understudied in the literature. Our current and future research include developing novel neural network based algorithms for such learning scenarios. 

__Selected Publications__ 

- [A Study of Incremental Spectral Meta-Learning for Nonstationary Environments](http://ieeexplore.ieee.org/abstract/document/7727178/) <br />
  G. Ditzler   <br />
  IEEE/INNS International Joint Conference on Neural Networks, 2016.
- [Adaptive strategies for learning in nonstationary environments: a survey](http://ieeexplore.ieee.org/document/7296710/)<br />
  G. Ditzler, M. Roveri, C. Alippi, and R. Polikar<br />
  IEEE Computational Intelligence Magazine, 2015, vol. 10, no. 4, pp. 12-25.  
- [Incremental learning of concept drift from streaming imbalanced data](http://ieeexplore.ieee.org/document/6235959/)<br />
  G. Ditzler and R. Polikar<br />
  IEEE Transactions on Knowledge & Data Engineering, 2013, vol. 25, no. 10, pp. 2283â€“2301.
- [Domain Adaptation Bounds for Multiple Expert Systems Under Concept Drift](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6889909) <br />
  G. Ditzler, G. Rosen, and R. Polikar <br />
  IEEE/INNS International Joint Conference on Neural Networks, 2014. (travel award & best student paper) 
  

## Large Scale Feature Selection 
There is an ever-increasing number of applications that are generating massive amounts of data, which are of high dimensionality. Not only is the cardinality of the data rapidly increasing, but also the dimensionality. Such applications include analysis of a vast amount of data generated by social networks, media networks, blogs, healthcare informatics and genomics to name a few. Unfortunately, not all of the features in the data informative or meaningful and we are completely unaware of which features are meaningful. Therefore, we need algorithms to extract the meaningful and informative features, while remaining scalable to a massive population of data. Our research in scalable feature selection is developing new algorithms to cope with such data. 

__Selected Publications__ 

- [A Fast Information-theoretic Approximation of Joint Mutual Information Feature Selection](http://ieeexplore.ieee.org/abstract/document/7966441/?reload=true) <br />
  H. Liu and G. Ditzler <br />
  IEEE/INNS International Joint Conference on Neural Networks, 2017.
- [A Sequential Learning Approach for Scaling up Filter-Based Feature Subset Selection](http://ieeexplore.ieee.org/abstract/document/7926436/)<br />
  G. Ditzler, R. Polikar, and G. Rosen<br />
  IEEE Transactions on Neural Networks and Learning Systems, 2017. (accepted)
- [A bootstrap based Neyman-Pearson test for identifying variable importance](http://ieeexplore.ieee.org/document/6823119/)<br />
  G. Ditzler, R. Polikar, and G. Rosen<br />
  IEEE Transactions on Neural Networks and Learning Systems, 2015, vol. 26, no. 4, pp. 880-886. 

## Machine Learning in Cybersecurity 
Advances in multi-core computing systems, networking, mobile and smart devices, complex software and Internet have enabled the development of revolutionary capabilities that have served many fields. However, along with these advances, vulnerabilities in the computing systems stemming from failure to enforce the semantics of computation, have led to an ever-increasing number of attacks and their sophistication leading to heavy financial losses. Our research group is developing online and adaptive algorithms, known as self-protective agents, that monitor activity on a network with many applications running. Furthermore, our research also focuses on adversarial machine learning, which has broader impacts in cybersecurity.

__Selected Publications__ 

- [A Self-Protection Agent using Error Correcting Output Codes to Secure Computers and Applications](http://ieeexplore.ieee.org/abstract/document/8064054/)  <br />
  F. de la Pena Montero, S. Hariri, and G. Ditzler <br />
  IEEE International Conference on Cloud and Autonomic Computing, 2017.


## Finding Insights in Life Sciences with Machine Learning 
Our group's research applies machine learning algorithms developed in the lab to metagenomics and other areas of the life sciences. Metagenomics is the study of genetic material obtained directly from an environmental sample, which means that everything is sequenced from a sample (i.e., all of the organisms). We have applied our feature selection expertise to 16S and metagenomic data to help microbial ecologists determine the protein families and microorganisms that best differentiate between multiple phenotypes within an environmental study.

We have  addressed the problem of inferring sparse time-varying networks from a set of under-sampled measurements. More formally,  we proposed the Approximate Kernel RecONstruction (AKRON) Kalman filter to reconstruct these time varying networks from data collected from the different life stages of a fruitfly.

__Selected Publications__ 

- [AKRON: An Algorithm for Approximating Sparse Kernel Reconstruction](http://www.sciencedirect.com/science/article/pii/S0165168417303791)<br />
  G. Ditzler, N. Bouaynaya, and R. Shterenberg <br />
  Signal Processing, 2017. To appear.
- [The AKRON-Kalman Filter for Tracking Time-Varying Networks](http://ieeexplore.ieee.org/abstract/document/7897268/) <br />
  V. Carluccio, N. Bouaynaya, G. Ditzler, and H. M. Fathallah Shaykh <br />
  IEEE International Conference on Biomedical and Health Informatics, 2017.
- [Fizzy: Feature selection for metagenomics](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0793-8)<br />
  G. Ditzler, J. Calvin Morrison, Y. Lan, and G. Rosen<br />
  BMC Bioinformatics, 2015, vol 16, no. 358. [code]
- [Feature Subset Selection for Inferring Relative Importance of Taxonomy](http://dl.acm.org/citation.cfm?id=2660824) <br />
  G. Ditzler and G. Rosen <br />
  ACM International Workshop on Big Data in Life Sciences, 2014. (invited and travel award)



